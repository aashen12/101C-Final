---
title: "Model 10b"
author: 'Ethan Allavarpu (UID: 405287603)'
date: "12/3/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
```

```{r}
training <- read.csv("training.csv", stringsAsFactors = FALSE)
dim(training)
any(is.na(training))
var_types <- vapply(training, class, character(1))
names(training)[-which(var_types %in% c("integer", "numeric"))]
```

```{r}
dates <- training$PublishedDate
head(dates)
split_dates <- strsplit(dates, "[:/ ]")
head(split_dates)
split_dates <- lapply(split_dates, as.numeric)
years <- function(date) {
  date[3]
}
yrs <- lapply(split_dates, years)
unique(yrs)  # Only 2020
new_time <- function(old_date) {
  old_date <- as.numeric(old_date)
  month <- old_date[1]
  day <- old_date[2]
  hr <- old_date[4]
  minute <- old_date[5]
  month_days <- c(31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)
  complete_months <- month - 1
  if (complete_months > 0) {
    complete_month_days <- sum(month_days[1:complete_months])
  } else {
    complete_month_days <- 0
  }
  total_days <- complete_month_days + day
  pre_hrs <- total_days * 24
  total_hrs <- pre_hrs + hr
  pre_min <- total_hrs * 60
  final_time <- pre_min + minute 
  final_time
}
processed_dates <- vapply(split_dates, new_time, numeric(1))
training$PublishedDate <- processed_dates
```

```{r}
subs <- training[, 248:250]
sub_final <- 3 - 3 * subs[[1]] - 2 * subs[[2]] - subs[[3]]
views <- training[, 251:253]
views_final <- 3 - 3 * views[[1]] - 2 * views[[2]] - views[[3]]
growth <- training[, 254:256]
growth_final <- 3 - 3 * growth[[1]] - 2 * growth[[2]] - growth[[3]]
vids <- training[, 257:259]
vid_final <- 3 - 3 * vids[[1]] - 2 * vids[[2]] - vids[[3]]
growth_2_6 <- training$growth_2_6
names(training)[c(1, 248:260)]
training <- training[, -c(1, 248:260)]
training <- data.frame(training, Num_Subscribers_Base = sub_final,
                       Num_Views_Base = views_final, avg_growth = growth_final,
                       count_vids = vid_final, growth_2_6 = growth_2_6)
```
```{r}
# See which variables have no variation (useless)
var_sds <- vapply(training, sd, numeric(1))
useless_vars <- names(training)[var_sds == 0]
useless_vars
training <- training[, !(names(training) %in% useless_vars)]
```
```{r}
# Remove highly correlated variables
cor_mtx <- round(cor(training[, -ncol(training)]), 2)
library(reshape2)
library(ggplot2)
melted_cor_mtx <- melt(cor_mtx)
cor_vars <- which(abs(cor_mtx) > 0.9, arr.ind = TRUE)
for (i in 1:nrow(cor_vars)) {
  if (cor_vars[i, 1] >= cor_vars[i, 2]) {
    cor_vars[i, ] <- rep(NA, 2)
  }
}

all_na <- function(data) {
  all(is.na(data))
}
unique_cor_vars <- apply(cor_vars, 1, all_na)
cor_vars <- cor_vars[!unique_cor_vars, ]
corr_vars <- unique(rownames(cor_vars))
```

```{r}
factor_vars <- training[, 235:238]
factor_vars <- data.frame(lapply(factor_vars, factor))
training[, 235:238] <- factor_vars
training <- training[, !(names(training) %in% corr_vars)]
```


```{r}
val_mses <- numeric(10)
set.seed(5341)
library(glmnet)
for (i in seq_len(10)) {
  data_split <- sample(nrow(training), nrow(training) * 0.8)
  train <- training[data_split, ]
  validation <- training[-data_split, ]
  train_x <- model.matrix(growth_2_6 ~ ., data = train)[, -1]
  train_y <- train$growth_2_6
  test_x <- model.matrix(growth_2_6 ~ ., data = validation)[, -1]
  lambda_grid <- 10^(seq(from = 10, to = -2, length.out = 100))
  salary_lasso <- glmnet(train_x, train_y, family = "gaussian",
                         alpha = 1, lambda = lambda_grid, standardize = TRUE)
  salary_lasso_cv <- cv.glmnet(train_x, train_y, family = "gaussian", alpha = 1,
                               lambda = lambda_grid, standardize = TRUE,
                               nfolds = 10)
  lambda_1se <- salary_lasso_cv$lambda.1se
  lasso_test_preds <- predict(salary_lasso, newx = test_x, s = lambda_1se)
  val_mses[i] <- mean((lasso_test_preds - validation$growth_2_6)^2)
}
mean(val_mses)
hist(val_mses)
data_split <- sample(nrow(training), nrow(training) * 0.8)
train <- training[data_split, ]
validation <- training[-data_split, ]
train_x <- model.matrix(growth_2_6 ~ ., data = train)[, -1]
train_y <- train$growth_2_6
test_x <- model.matrix(growth_2_6 ~ ., data = validation)[, -1]
lambda_grid <- 10^(seq(from = 10, to = -2, length.out = 100))
salary_lasso <- glmnet(train_x, train_y, family = "gaussian",
                         alpha = 1, lambda = lambda_grid, standardize = TRUE)
salary_lasso_cv <- cv.glmnet(train_x, train_y, family = "gaussian", alpha = 1,
                               lambda = lambda_grid, standardize = TRUE,
                               nfolds = 10)
lambda_1se <- salary_lasso_cv$lambda.1se
lasso_coefs <- predict(salary_lasso, newx = test_x,
                       s = lambda_1se, type = "coefficients")[, 1]
keep_vars <- names(lasso_coefs)[lasso_coefs != 0][-1]
```
```{r}
keep_vars <- c(keep_vars[1:47], names(training)[(ncol(training) - 4):(ncol(training) - 1)])
```

```{r}
library(randomForest)
set.seed(100)
data_split <- sample(nrow(training), nrow(training) * 0.8)
train <- training[data_split, ]
validation <- training[-data_split, ]
train_bag <- train[, c(keep_vars, "growth_2_6")]
# -1 from ncol() because one column is the response variable
p <- ncol(train_bag) - 1 # Total number of predictors = 59
m_vals <- floor(seq(from = 1, to = p, length.out = 25))
```

```{r}
create_best_m <- function(m_val, train_data = training, split = 0.8,
                          num_tree = 25, keep_vars = names(train_data),
                          seed = 1, nodesize = 5) {
  set.seed(seed)
  data_split <- sample(nrow(train_data), nrow(train_data) * 0.8)
  train <- train_data[data_split, keep_vars]
  validation <- train_data[-data_split, ]
  bag_tree <- randomForest(growth_2_6 ~ ., data = train,
                            mtry = m_val, ntree = num_tree,
                            nodesize = nodesize)
  bag_preds <- predict(bag_tree, newdata = validation)
  bag_mse <- mean((validation$growth_2_6 - bag_preds)^2)
  rmses <- sqrt(bag_mse)
  rmses
}
rmses <- list()
length(rmses) <- 5
set.seed(1235)
  rmses <- vapply(m_vals, create_best_m, numeric(1),
                       train_data = training,
                       keep_vars = c(keep_vars, "growth_2_6"),
                       num_tree = 50, seed = 3213, nodesize = 20)
```


```{r}
plot(m_vals, rmses, type = "l")
```
```{r}
set.seed(9078)
data_split <- sample(nrow(training), nrow(training) * 0.8)
train <- training[data_split, c(keep_vars, "growth_2_6")]
validation <- training[-data_split, ]
bag_tree <- randomForest(growth_2_6 ~ ., data = train,
                            mtry = p, ntree = 1000,
                         nodesize = 10)
bag_preds <- predict(bag_tree, newdata = validation)
bag_mse <- mean((validation$growth_2_6 - bag_preds)^2)
rmse <- sqrt(bag_mse)
rmse
```



```{r}
test <- read.csv("test.csv")
dates <- test$PublishedDate
split_dates <- strsplit(dates, "[:/ ]")
split_dates <- lapply(split_dates, as.numeric)
years <- function(date) {
  date[3]
}
yrs <- lapply(split_dates, years)
unique(yrs)
processed_dates <- vapply(split_dates, new_time, numeric(1))
test$PublishedDate <- processed_dates
subs <- test[, 248:250]
sub_final <- 3 - 3 * subs[[1]] - 2 * subs[[2]] - subs[[3]]
views <- test[, 251:253]
views_final <- 3 - 3 * views[[1]] - 2 * views[[2]] - views[[3]]
growth <- test[, 254:256]
growth_final <- 3 - 3 * growth[[1]] - 2 * growth[[2]] - growth[[3]]
vids <- test[, 257:259]
vid_final <- 3 - 3 * vids[[1]] - 2 * vids[[2]] - vids[[3]]
id <- test$id
test <- test[, -c(1, 248:260)]
test <- data.frame(test, Num_Subscribers_Base = sub_final,
                       Num_Views_Base = views_final, avg_growth = growth_final,
                       count_vids = vid_final)
factor_vars <- test[, 247:250]
factor_vars <- data.frame(lapply(factor_vars, factor))
test[, 247:250] <- factor_vars
bag_test_preds <- predict(bag_tree, newdata = test)
test_csv <- data.frame(id = id, growth_2_6 = bag_test_preds)
write.csv(test_csv, "model10bpredictions.csv", row.names = FALSE)
```

## Boosting Code (if necessary)
```{r}
library(gbm)
set.seed(101)
lambdas <- 10^seq(from = -10, to = 0, length.out = 25)
salary_boosted <- list()
length(salary_boosted) <- length(lambdas)
boost_train_mses <- numeric(length(lambdas))
for (i in seq_along(lambdas)) {
  salary_boosted[[i]] <- gbm(growth_2_6 ~ ., data = train_bag,
                             distribution = "gaussian", n.trees = 500,
                             shrinkage = lambdas[i])
  boost_train_preds <- predict(salary_boosted[[i]], newdata = validation,
                               n.trees = 500)
  boost_train_mses[i] <- mean((validation$growth_2_6 - boost_train_preds)^2)
}
plot(x = lambdas, y = boost_train_mses,
     main = expression(paste("Training MSE vs. ", lambda)),
     xlab = expression(lambda), ylab = "Training MSE",
     pch = 19, cex = 0.5, col = rgb(0.5, 0, 0, alpha = 0.5), las = 1)
```
