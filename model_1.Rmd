---
title: "Model 1"
author: "Ethan Allavarpu, Andy Shen"
date: "11/30/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
```

```{r}
training <- read.csv("training.csv", stringsAsFactors = FALSE)
dim(training)
any(is.na(training))
var_types <- vapply(training, class, character(1))
names(training)[-which(var_types %in% c("integer", "numeric"))]
```

```{r}
dates <- training$PublishedDate
head(dates)
split_dates <- strsplit(dates, "[:/ ]")
head(split_dates)
split_dates <- lapply(split_dates, as.numeric)
years <- function(date) {
  date[3]
}
yrs <- lapply(split_dates, years)
unique(yrs)  # Only 2020
new_time <- function(old_date) {
  old_date <- as.numeric(old_date)
  month <- old_date[1]
  day <- old_date[2]
  hr <- old_date[4]
  minute <- old_date[5]
  month_days <- c(31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)
  complete_months <- month - 1
  if (complete_months > 0) {
    complete_month_days <- sum(month_days[1:complete_months])
  } else {
    complete_month_days <- 0
  }
  total_days <- complete_month_days + day
  pre_hrs <- total_days * 24
  total_hrs <- pre_hrs + hr
  pre_min <- total_hrs * 60
  final_time <- pre_min + minute 
  final_time
}
processed_dates <- vapply(split_dates, new_time, numeric(1))
training$PublishedDate <- processed_dates
```

```{r}
factor_vars <- training[, 248:259]
factor_vars <- data.frame(lapply(factor_vars, factor))
training[, 248:259] <- factor_vars
```
```{r}
val_mses <- numeric(10)
set.seed(1234567890)
library(glmnet)
for (i in seq_len(10)) {
  data_split <- sample(nrow(training), nrow(training) * 0.8)
  train <- training[data_split, ]
  validation <- training[-data_split, ]
  train_x <- model.matrix(growth_2_6 ~ ., data = train)[, -1]
  train_y <- train$growth_2_6
  test_x <- model.matrix(growth_2_6 ~ ., data = validation)[, -1]
  lambda_grid <- 10^(seq(from = 10, to = -2, length.out = 100))
  salary_lasso <- glmnet(train_x, train_y, family = "gaussian",
                         alpha = 1, lambda = lambda_grid, standardize = TRUE)
  salary_lasso_cv <- cv.glmnet(train_x, train_y, family = "gaussian", alpha = 1,
                               lambda = lambda_grid, standardize = TRUE,
                               nfolds = 10)
  lambda_1se <- salary_lasso_cv$lambda.1se
  lasso_test_preds <- predict(salary_lasso, newx = test_x, s = lambda_1se)
  val_mses[i] <- mean((lasso_test_preds - validation$growth_2_6)^2)
}
mean(val_mses)
hist(val_mses)
data_split <- sample(nrow(training), nrow(training) * 0.8)
train <- training[data_split, ]
validation <- training[-data_split, ]
train_x <- model.matrix(growth_2_6 ~ ., data = train)[, -1]
train_y <- train$growth_2_6
test_x <- model.matrix(growth_2_6 ~ ., data = validation)[, -1]
lambda_grid <- 10^(seq(from = 10, to = -2, length.out = 100))
salary_lasso <- glmnet(train_x, train_y, family = "gaussian",
                         alpha = 1, lambda = lambda_grid, standardize = TRUE)
salary_lasso_cv <- cv.glmnet(train_x, train_y, family = "gaussian", alpha = 1,
                               lambda = lambda_grid, standardize = TRUE,
                               nfolds = 10)
lambda_1se <- salary_lasso_cv$lambda.1se
lasso_coefs <- predict(salary_lasso, newx = test_x,
                       s = lambda_1se, type = "coefficients")[, 1]
keep_vars <- names(lasso_coefs)[lasso_coefs != 0][-1]
keep_vars[58:64] <- c("Num_Subscribers_Base_low_mid", "Num_Views_Base_low_mid", "Num_Views_Base_mid_high",
                      "avg_growth_low", "avg_growth_low_mid", "avg_growth_mid_high", "count_vids_low_mid")
```

```{r}
cor_mtx <- round(cor(training[, keep_vars]), 2)
library(reshape2)
library(ggplot2)
melted_cor_mtx <- melt(cor_mtx)
cor_heatmap <- ggplot(data = melted_cor_mtx, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile()
cor_heatmap <- cor_heatmap +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0,
                       limit = c(-1, 1), space = "Lab", name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1))
cor_heatmap
which(abs(cor_mtx) > 0.5, arr.ind = TRUE)
library(dplyr)
correlated <- c("hog_675", "cnn_89", "cnn_17", "cnn_25", "cnn_88", "num_words")
keep_vars_train <- training[, keep_vars][, !(keep_vars %in% correlated)]
keep_vars <- keep_vars[!(keep_vars %in% correlated)]
```

```{r}
library(randomForest)
set.seed(0)
train_bag <- train[, c(keep_vars, "growth_2_6")]
# -1 from ncol() because one column is the response variable
p <- ncol(train_bag) - 1 # Total number of predictors = 59
p
bag_tree <- randomForest(growth_2_6 ~ ., data = train_bag,
                         mtry = p, ntree = 25)
bag_preds <- predict(bag_tree, newdata = validation)
bag_mse <- mean((validation$growth_2_6 - bag_preds)^2)
sqrt(bag_mse)
#tuned_forest <- tuneRF(train[, -ncol(train)], train$growth_2_6, stepFactor = 1.5, mtry = p, improve = 0.025)

```


```{r}
test <- read.csv("test.csv")
dates <- test$PublishedDate
split_dates <- strsplit(dates, "[:/ ]")
split_dates <- lapply(split_dates, as.numeric)
years <- function(date) {
  date[3]
}
yrs <- lapply(split_dates, years)
unique(yrs)
processed_dates <- vapply(split_dates, new_time, numeric(1))
test$PublishedDate <- processed_dates
factor_vars <- test[, 248:259]
factor_vars <- data.frame(lapply(factor_vars, factor))
test[, 248:259] <- factor_vars
bag_test_preds <- predict(bag_tree, newdata = test)
test_csv <- data.frame(id = test$id, growth_2_6 = bag_test_preds)
write.csv(test_csv, "model1predictions.csv", row.names = FALSE)
```


